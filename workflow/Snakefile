import os


configfile: "config/config.yaml"

def get_resource(rule, resource):
    try:
        return config["resources"][rule][resource]
    except KeyError:
        return config["resources"]["default"][resource]

regions = {}
with open(config["regions"]) as ifh:
    fields = ["chrom","start","end","label","score","strand"]
    for l in ifh:
        data = l.rstrip("\n").split()
        regions[data[3]] = dict(zip(fields,data))

def input_main(wc):
    o = []
    for patient in config["samples"]:
        o.append(f"results/methylartist_scoredist/{patient}.svg")
        normal=False
        for sampleid in config["samples"][patient]:
            s = config["samples"][patient][sampleid]
            if "normal" in s and s["normal"]:
                normal = sampleid
        for sampleid in config["samples"][patient]:
            o.append(f"results/pycoqc/{patient}/{sampleid}.html")
            o.append(f"results/primary/{patient}/{sampleid}.cov")
            o.append(f"results/mosdepth/{patient}/{sampleid}.mosdepth.global.dist.txt")
            o.append(f"results/modkit/pileup/{patient}/{sampleid}.bed")
            o.append(f"results/sniffles/{patient}/{sampleid}.vcf.gz")
            o.append(f"results/severus/{patient}/{sampleid}")
            o.append(f"results/smoothcov/{patient}/{sampleid}.csv")
            if normal and normal != sampleid:
                o.append(f"results/clairs/{patient}/{sampleid}/output.vcf.gz")
    if config["run_methylartist"]:
        for patient in config["samples"]:
            for label in regions:
                o.append(f"results/methylartist/{patient}/{label}.png")
    return o


rule main:
    input:
        input_main,


rule basecall_dorado:
    input:
        lambda wc: config["samples"][wc.patient][wc.sampleid]["pod5"],
    output:
        "results/basecall_dorado/{patient}/{sampleid}.bam",
    log:
        "logs/basecall_dorado/{patient}/{sampleid}.log",
    benchmark:
        "logs/basecall_dorado/{patient}/{sampleid}.bmk"
    params:
        bin=config["dorado_bin"],
        model=get_resource("basecall_dorado", "params_model"),
        extra=get_resource("basecall_dorado", "params_extra"),
    threads: get_resource("basecall_dorado", "threads")
    resources:
        mem_mb=get_resource("basecall_dorado", "mem_mb"),
        runtime=get_resource("basecall_dorado", "runtime"),
        slurm_partition=get_resource("basecall_dorado", "partition"),
        slurm_extra=get_resource("basecall_dorado", "slurm_extra"),
    shell:
        """
        {params.bin} basecaller {params.model} {input} {params.extra} > {output} 2> {log}
    """


rule summary_dorado:
    input:
        "results/basecall_dorado/{sampleid}.bam",
    output:
        "results/summary_dorado/{sampleid}.txt",
    log:
        "logs/summary_dorado/{sampleid}.log",
    benchmark:
        "logs/summary_dorado/{sampleid}.bmk"
    params:
        bin=config["dorado_bin"],
    threads: get_resource("summary_dorado", "threads")
    resources:
        mem_mb=get_resource("summary_dorado", "mem_mb"),
        runtime=get_resource("summary_dorado", "runtime"),
        slurm_partition=get_resource("summary_dorado", "partition"),
        slurm_extra=get_resource("summary_dorado", "slurm_extra"),
    shell:
        """
        {params.bin} summary {input} >> {output} 2> {log}
    """


rule pycoqc:
    input:
        "results/summary_dorado/{sampleid}.txt",
    output:
        "results/pycoqc/{sampleid}.html",
    log:
        "logs/pycoqc/{sampleid}.log",
    benchmark:
        "logs/pycoqc/{sampleid}.bmk"
    threads: get_resource("pycoqc", "threads")
    conda:
        "envs/pycoqc.yaml"
    resources:
        mem_mb=get_resource("pycoqc", "mem_mb"),
        runtime=get_resource("pycoqc", "runtime"),
        slurm_partition=get_resource("pycoqc", "partition"),
        slurm_extra=get_resource("pycoqc", "slurm_extra"),
    shell:
        """
       pycoQC -f {input} -o {output} 2>&1 > {log}
    """

rule qsfilter:
    input:
        "results/basecall_dorado/{sampleid}.bam",
    output:
        "results/qsfilter/{sampleid}.bam",
    log:
        "logs/qsfilter/{sampleid}.log",
    benchmark:
        "logs/qsfilter/{sampleid}.bmk"
    params:
        minq=config["minq"]
    threads: get_resource("qsfilter", "threads")
    resources:
        mem_mb=get_resource("qsfilter", "mem_mb"),
        runtime=get_resource("qsfilter", "runtime"),
        slurm_partition=get_resource("qsfilter", "partition"),
    conda:
        "envs/samtools.yaml"
    shell:
        """
        samtools view -e '[qs]>={params.minq}' {input} > {output} 2> {log}
    """


rule minimap2:
    input:
        reads="results/qsfilter/{patient}/{sampleid}.bam",
        ref=lambda wc: config["ref"],
    output:
        "results/minimap2/{patient}/{sampleid}.bam",
    log:
        "logs/minimap2/{patient}/{sampleid}.log",
    benchmark:
        "logs/minimap2/{patient}/{sampleid}.bmk"
    threads: get_resource("minimap2", "threads")
    resources:
        mem_mb=get_resource("minimap2", "mem_mb"),
        runtime=get_resource("minimap2", "runtime"),
        slurm_partition=get_resource("minimap2", "partition"),
    conda:
        "envs/minimap2.yaml"
    shell:
        """
        samtools fastq -T "*" {input.reads} | minimap2 -a -x map-ont -y -t {threads} {input.ref} - | samtools sort - -o {output} 2> {log}
        samtools index {output}
    """

rule primary:
    input:
        "results/minimap2/{patient}/{sampleid}.bam",
    output:
        bam="results/primary/{patient}/{sampleid}.bam",
        bai="results/primary/{patient}/{sampleid}.bam.bai",
    log:
        "logs/primary/{patient}/{sampleid}.log",
    benchmark:
        "logs/primary/{patient}/{sampleid}.bmk"
    threads: lambda wc: get_resource("primary", "threads")/2
    resources:
        mem_mb=get_resource("primary", "mem_mb"),
        runtime=get_resource("primary", "runtime"),
        slurm_partition=get_resource("primary", "partition"),
    conda:
        "envs/samtools.yaml"
    shell:
        """
        samtools view -@ {threads} -F 2308 -b {input} | samtools sort -@ {threads} -o {output.bam} 2> {log}
        samtools index {output.bam}
    """

def get_bams(wc):
        for sampleid in config["samples"][wc.patient]:
            yield f"results/primary/{wc.patient}/{sampleid}.bam"

rule methylartist_scoredist:
    input:
        bams=get_bams,
        ref="results/decompress_ref/ref.fa",
    output:
        "results/methylartist_scoredist/{patient}.svg",
    log:
        "logs/methylartist_scoredist/{patient}.log",
    benchmark:
        "logs/methylartist_scoredist/{patient}.bmk"
    resources:
        mem_mb=get_resource("methylartist_scoredist", "mem_mb"),
        runtime=get_resource("methylartist_scoredist", "runtime"),
        slurm_partition=get_resource("methylartist_scoredist", "partition"),
    params:
        bams=lambda wc: ",".join(get_bams(wc))
    conda:
        "envs/methylartist.yaml"
    shell:
        """
        methylartist scoredist --ref {input.ref} --motif CG -b {params.bams} -o {output} -m m --svg &> {log}
    """

rule coverage:
    input:
        "results/primary/{patient}/{sampleid}.bam",
    output:
        "results/primary/{patient}/{sampleid}.cov",
    log:
        "logs/coverage/{patient}/{sampleid}.log",
    benchmark:
        "logs/coverage/{patient}/{sampleid}.bmk"
    resources:
        mem_mb=get_resource("coverage", "mem_mb"),
        runtime=get_resource("coverage", "runtime"),
        slurm_partition=get_resource("coverage", "partition"),
    conda:
        "envs/samtools.yaml"
    shell:
        """
        samtools coverage -A -o {output} {input} &> {log}
    """

rule mosdepth:
    input:
        bam="results/primary/{patient}/{sampleid}.bam",
        bai="results/primary/{patient}/{sampleid}.bam.bai",
    output:
        "results/mosdepth/{patient}/{sampleid}.mosdepth.global.dist.txt",
        "results/mosdepth/{patient}/{sampleid}.mosdepth.region.dist.txt",
        "results/mosdepth/{patient}/{sampleid}.per-base.bed.gz",
        "results/mosdepth/{patient}/{sampleid}.regions.bed.gz",
        summary="results/mosdepth/{patient}/{sampleid}.mosdepth.summary.txt",
    log:
        "logs/mosdepth/{patient}/{sampleid}.log",
    benchmark:
        "logs/mosdepth/{patient}/{sampleid}.bmk"
    threads: get_resource("mosdepth", "threads"),
    resources:
        mem_mb=get_resource("mosdepth", "mem_mb"),
        runtime=get_resource("mosdepth", "runtime"),
        slurm_partition=get_resource("mosdepth", "partition"),
    params:
        extra="--fast-mode",
        by="1000",
    wrapper:
        "v5.2.1/bio/mosdepth"

rule modkit_pileup:
    input:
        bam="results/primary/{patient}/{sampleid}.bam",
        bai="results/primary/{patient}/{sampleid}.bam.bai",
    output:
        bed="results/modkit/pileup/{patient}/{sampleid}.bed",
    log:
        "logs/modkit/pileup/{patient}/{sampleid}.log",
    benchmark:
        "logs/modkit/pileup/{patient}/{sampleid}.bmk"
    conda: "envs/modkit.yaml"
    threads: get_resource("modkit_pileup", "threads"),
    resources:
        mem_mb=get_resource("modkit_pileup", "mem_mb"),
        runtime=get_resource("modkit_pileup", "runtime"),
        slurm_partition=get_resource("modkit_pileup", "partition"),
    shell:"""
        modkit pileup {input.bam} {output.bed} \
          --threads {threads} \
          --log-filepath {log}
    """

rule decompress_ref:
    input:
        ref=config["ref"],
    output:
        ref=temp("results/decompress_ref/ref.fa"),
        idx=temp("results/decompress_ref/ref.fa.fai")
    log:
        "logs/decompress_ref/ref.out",
    conda: "envs/samtools.yaml"
    shell:"""
        gunzip -c {input.ref} > {output.ref} 2> {log}
        samtools faidx {output.ref} 2>> {log}
    """

def get_region(wc):
    region = regions[wc.label]
    chrom = region['chrom']
    start = int(region['start']) - 5000
    end = int(region['end']) + 5000
    return f"{chrom}:{start}-{end}"

def get_colored_bams(wc, input):
    bamc = []
    for bam in input.bams:
        sid = os.path.splitext(os.path.basename(bam))[0]
        try:
            colour = config["samples"][wc.patient][sid]["colour"]
            bamc.append(f"{bam}:{colour}")
        except KeyError:
            bamc.append(bam)
    return ",".join(bamc)

def get_time_retry(wc, attempt):
    return attempt * get_resource("methylartist", "runtime")

rule methylartist:
    input:
        bams=get_bams,
        ann=config["ann"],
        ref="results/decompress_ref/ref.fa",
        hl=config["highlights"],
    output:
        png="results/methylartist/{patient}/{label}.png"
    log:
        o="logs/methylartist/{patient}/{label}.out",
        e="logs/methylartist/{patient}/{label}.err",
    benchmark:
        "logs/methylartist/{patient}/{label}.bmk"
    params:
        reg=get_region,
        bams=get_colored_bams,
    conda: "envs/methylartist.yaml"
    threads: get_resource("methylartist", "threads"),
    resources:
        mem_mb=get_resource("methylartist", "mem_mb"),
        runtime=get_time_retry,
        slurm_partition=get_resource("methylartists", "partition"),
    retries: 4
    shell:"""
        methylartist locus \
                -b {params.bams} \
                -g {input.ann} \
                -p {threads} \
                -n CG \
                --mods m \
                --labelgenes \
                -r {input.ref} \
                -o {output.png} \
                --highlight_bed {input.hl} \
                -i "{params.reg}" \
                --panelratios 1,5,1,3,3 \
                > {log.o} 2> {log.e}
    """

rule sniffles:
    input:
        bam="results/primary/{patient}/{sampleid}.bam",
        ref="results/decompress_ref/ref.fa",
    output:
        vcf="results/sniffles/{patient}/{sampleid}.vcf.gz",
    log:
        "logs/sniffles/{patient}/{sampleid}.log",
    benchmark:
        "logs/sniffles/{patient}/{sampleid}.bmk"
    threads: get_resource("sniffles", "threads"),
    resources:
        mem_mb=get_resource("sniffles", "mem_mb"),
        runtime=get_resource("sniffles", "runtime"),
        slurm_partition=get_resource("sniffles", "partition"),
    conda: "envs/sniffles.yaml"
    shell:"""
        sniffles --input {input.bam} --vcf {output.vcf} -t {threads} --reference {input.ref} --mosaic --mosaic-include-germline &> {log}
    """

rule clair3:
    input:
        bam="results/primary/{patient}/{sampleid}.bam",
        ref="results/decompress_ref/ref.fa",
        idx="results/decompress_ref/ref.fa.fai",
    output:
        full="results/clair3/{patient}/{sampleid}/full_alignment.vcf.gz",
        merge="results/clair3/{patient}/{sampleid}/merge_output.vcf.gz",
        pileup="results/clair3/{patient}/{sampleid}/pileup.vcf.gz",
        phased_vcf="results/clair3/{patient}/{sampleid}/phased_merge_output.vcf.gz",
        phased_bam="results/clair3/{patient}/{sampleid}/phased_output.bam",
    log:
        "logs/clair3/{patient}/{sampleid}.log",
    benchmark:
        "logs/clair3/{patient}/{sampleid}.bmk"
    threads: get_resource("clair3", "threads"),
    resources:
        mem_mb=get_resource("clair3", "mem_mb"),
        runtime=get_resource("clair3", "runtime"),
        slurm_partition=get_resource("clair3", "partition"),
    params:
        model=config["clair3_model"]
    conda: "envs/clair3.yaml"
    shell: """
      run_clair3.sh \
          --bam_fn={input.bam} \
          --ref_fn={input.ref} \
          --threads={threads} \
          --platform="ont" \
          --model_path="{params.model}" \
          --output=$(dirname {output.full}) \
          --enable_phasing \
          --include_all_ctgs \
          --use_whatshap_for_intermediate_phasing \
          --use_whatshap_for_final_output_phasing \
          --use_whatshap_for_final_output_haplotagging &> {log}
    """

def get_normal_severus(wc):
    """use 'normal' sample as control if available"""

    for sample in config["samples"][wc.patient]:
        s = config["samples"][wc.patient][sample]
        # check that there's a control sample for the patient, and that it's not
        # the same sample as the target
        if sample != wc.sampleid and "normal" in s and s["normal"]:
            return f" --control-bam results/clair3/{wc.patient}/{sample}/phased_output.bam"
    return ""

rule severus:
    input:
        vcf="results/clair3/{patient}/{sampleid}/phased_merge_output.vcf.gz",
        bam_tumour="results/clair3/{patient}/{sampleid}/phased_output.bam",
    output:
        directory("results/severus/{patient}/{sampleid}")
    log:
        "logs/severus/{patient}/{sampleid}.log",
    benchmark:
        "logs/severus/{patient}/{sampleid}.bmk"
    threads: get_resource("severus", "threads"),
    resources:
        mem_mb=get_resource("severus", "mem_mb"),
        runtime=get_resource("severus", "runtime"),
        slurm_partition=get_resource("severus", "partition"),
    params:
        vntrs=config["severus_vntrs"],
        bam_normal=get_normal_severus,
    conda: "envs/severus.yaml"
    shell: """
        ln -sf $(basename {input.bam_tumour}) $(dirname {input.bam_tumour})/tumour.bam
        ln -sf $(basename {input.bam_tumour}).bai $(dirname {input.bam_tumour})/tumour.bam.bai
        severus \
            --target-bam $(dirname {input.bam_tumour})/tumour.bam {params.bam_normal} \
            --out-dir {output}  \
            -t {threads} \
            --phasing-vcf {input.vcf} \
            --vntr-bed {params.vntrs} &> {log}
    """

def get_normal_bam(wc):
    """use 'normal' sample as control if available"""

    for sample in config["samples"][wc.patient]:
        s = config["samples"][wc.patient][sample]
        # check that there's a control sample for the patient, and that it's not
        # the same sample as the target
        if sample != wc.sampleid and "normal" in s and s["normal"]:
            return f"results/primary/{wc.patient}/{sample}.bam"

    raise ValueError("Couldn't locate normal sample")


rule clairs:
    input:
        bam_tumour="results/primary/{patient}/{sampleid}.bam",
        bam_normal = lambda wc : get_normal_bam,
        ref="results/decompress_ref/ref.fa",
    output:
        "results/clairs/{patient}/{sampleid}/output.vcf.gz"
    log:
        "logs/clairs/{patient}/{sampleid}.log",
    benchmark:
        "logs/clairs/{patient}/{sampleid}.bmk",
    threads: get_resource("clairs", "threads")
    resources:
        mem_mb=get_resource("clairs", "mem_mb"),
        runtime=get_resource("clairs", "runtime"),
        slurm_partition=get_resource("clairs", "partition")
    container: "docker://hkubal/clairs:latest" 
    conda:
        "envs/clairs.yaml"
    shell:"""
        run_clairs \
            --tumor_bam_fn /{input.bam_tumour} \
            --normal_bam_fn /{input.bam_normal} \
            --ref_fn /{input.ref} \
            --threads {threads} \
            -p ont_r10_dorado_sup_5khz \
            -P /models/r1041_e82_400bps_sup_v420/pileup.pkl \
            -F /models/r1041_e82_400bps_sup_v420/full_alignment.pkl \
            --clair3_model_path /models/clair3_models/r1041_e82_400bps_sup_v420 \
            --include_all_ctgs \
            --output_dir $(dirname /{output})
    """


rule smoothcov:
    input:
        bed="results/mosdepth/{patient}/{sampleid}.per-base.bed.gz"
    output:
        "results/smoothcov/{patient}/{sampleid}.csv"
    log:
        "logs/smoothcov/{patient}/{sampleid}.log"
    benchmark:
        "logs/smoothcov/{patient}/{sampleid}.bmk"
    resources:
        mem_mb=get_resource("smoothcov", "mem_mb"),
        runtime=get_resource("smoothcov", "runtime"),
        slurm_partition=get_resource("smoothcov", "partition")
    params:
        bin=config["smoothcov"]["bin"],
        chunk=config["smoothcov"]["chunk"],
        spike=config["smoothcov"]["spike"],
        smooth=config["smoothcov"]["smooth"]
    conda:
        "envs/smoothcov.yaml"
    script:
        "scripts/smoothcov.py"
